{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the OpenAI flagging and clean out any remotely offensive data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI is super strict with finetuning. We have to remove anything even remotely offensive from the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('personas_and_tweets.df.pkl')\n",
    "df['flagged'] = None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harassment': 0.04012942841051969,\n",
       " 'harassment_threatening': 0.000957539514024588,\n",
       " 'hate': 0.007229441470329221,\n",
       " 'hate_threatening': 1.0889691002655445e-05,\n",
       " 'illicit': 3.459916031782155e-05,\n",
       " 'illicit_violent': 1.1061159714638084e-05,\n",
       " 'self_harm': 0.0005058990298734508,\n",
       " 'self_harm_instructions': 0.00022597546832214694,\n",
       " 'self_harm_intent': 0.00023231015172245714,\n",
       " 'sexual': 0.0007293448983675677,\n",
       " 'sexual_minors': 9.028039015031105e-06,\n",
       " 'violence': 0.016203406374785012,\n",
       " 'violence_graphic': 8.349627818261147e-06,\n",
       " 'harassment/threatening': 0.000957539514024588,\n",
       " 'hate/threatening': 1.0889691002655445e-05,\n",
       " 'illicit/violent': 1.1061159714638084e-05,\n",
       " 'self-harm/intent': 0.00023231015172245714,\n",
       " 'self-harm/instructions': 0.00022597546832214694,\n",
       " 'self-harm': 0.0005058990298734508,\n",
       " 'sexual/minors': 9.028039015031105e-06,\n",
       " 'violence/graphic': 8.349627818261147e-06}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responsejson['results'][0]['category_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALELIZED\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "openaiclient = OpenAI(api_key=\"xxx\")\n",
    "\n",
    "# Function to process each row\n",
    "def process_row(index, row):\n",
    "    if 'flagged' in df.columns and pd.notnull(row.get('flagged')):\n",
    "        return None  # Skip processing if already flagged\n",
    "\n",
    "    response = openaiclient.moderations.create(\n",
    "        model=\"omni-moderation-latest\",\n",
    "        input=row['message'],\n",
    "    )\n",
    "\n",
    "    flagged = response.results[0].flagged\n",
    "    result_data = {\n",
    "        'index': index,\n",
    "        'flagged': flagged,\n",
    "        'category_scores': response.model_dump()['results'][0]['category_scores']\n",
    "    }\n",
    "    \n",
    "    return result_data\n",
    "\n",
    "# Using ThreadPoolExecutor for parallel processing\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:  # Adjust max_workers as needed\n",
    "    futures = [executor.submit(process_row, index, row) for index, row in df.iterrows()]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            df.at[result['index'], 'flagged'] = result['flagged']\n",
    "            for k, v in result['category_scores'].items():\n",
    "                df.at[result['index'], k] = v\n",
    "\n",
    "        # Save progress periodically\n",
    "        if result and result['index'] % 100 == 0:\n",
    "            df.to_pickle('personas_and_tweets_flagged2.df.pkl')\n",
    "\n",
    "# Final save\n",
    "df.to_pickle('personas_and_tweets_flagged2.df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON-PARALLELIZED\n",
    "\n",
    "from openai import OpenAI\n",
    "openaiclient = OpenAI(api_key=\"xxx\")\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "        # Check if persona already exists to avoid redundant processing\n",
    "        if 'flagged' in df.columns and pd.notnull(row.get('flagged')):\n",
    "            continue\n",
    "\n",
    "        # Get user summary and persona\n",
    "\n",
    "        response = openaiclient.moderations.create(\n",
    "            model=\"omni-moderation-latest\",\n",
    "            input=row['message'],\n",
    "        )\n",
    "        print(f'{row['message']}: {response.results[0].flagged}')\n",
    "\n",
    "        df.at[index, 'flagged'] = response.results[0].flagged\n",
    "\n",
    "        # Set all the properties\n",
    "        responsejson = response.model_dump()\n",
    "        for k,v in responsejson['results'][0]['category_scores'].items():\n",
    "            df.at[index, k] = v\n",
    "\n",
    "        df.to_pickle('personas_and_tweets_flagged2.df.pkl')\n",
    "\n",
    "\n",
    "df.to_pickle('personas_and_tweets_flagged2.df.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openaiclient = OpenAI(api_key=\"xx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openaiclient.moderations.create(\n",
    "    model=\"omni-moderation-latest\",\n",
    "    input=df.at[0,'message'],\n",
    ")\n",
    "# print(f'{row['message']}: {response.results[0].flagged}')\n",
    "# df.at[index, 'flagged'] = response.results[0].flagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsejson = response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harassment': 0.04012942841051969,\n",
       " 'harassment_threatening': 0.000957539514024588,\n",
       " 'hate': 0.007229441470329221,\n",
       " 'hate_threatening': 1.0889691002655445e-05,\n",
       " 'illicit': 3.459916031782155e-05,\n",
       " 'illicit_violent': 1.1061159714638084e-05,\n",
       " 'self_harm': 0.0005058990298734508,\n",
       " 'self_harm_instructions': 0.00022597546832214694,\n",
       " 'self_harm_intent': 0.00023231015172245714,\n",
       " 'sexual': 0.0007293448983675677,\n",
       " 'sexual_minors': 9.028039015031105e-06,\n",
       " 'violence': 0.016203406374785012,\n",
       " 'violence_graphic': 8.349627818261147e-06,\n",
       " 'harassment/threatening': 0.000957539514024588,\n",
       " 'hate/threatening': 1.0889691002655445e-05,\n",
       " 'illicit/violent': 1.1061159714638084e-05,\n",
       " 'self-harm/intent': 0.00023231015172245714,\n",
       " 'self-harm/instructions': 0.00022597546832214694,\n",
       " 'self-harm': 0.0005058990298734508,\n",
       " 'sexual/minors': 9.028039015031105e-06,\n",
       " 'violence/graphic': 8.349627818261147e-06}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responsejson['results'][0]['category_scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the cleaning out elsewhere..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
